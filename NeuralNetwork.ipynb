{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOhpLx6rvT12b8mMtX6Kwp"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNnkvpDnO-c5"
      },
      "outputs": [],
      "source": [
        "# f(x₁,x₂,x₃) = w₁₁*x₁ + w₁₂*x₂ + w₁₃*x₃ + b₁₁\n",
        "# A₁ = g(f(x₁,x₂,x₃)) = g(w₁₁*x₁ + w₁₂*x₂ + w₁₃*x₃ + b₁₁)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def relu(z):\n",
        "  return np.maximum(0, z)"
      ],
      "metadata": {
        "id": "5crPYxeSaPFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_params(layer_sizes): #takes a list of the layer sizes as input and returns initialized parameters eg: [2, 5, 3]\n",
        "    params = {}\n",
        "    for i in range(1, len(layer_sizes)):\n",
        "      params['W' + str(i)] = np.random.randn(layer_sizes[i], layer_sizes[i-1]) * 0.01\n",
        "      params['B' + str(i)] = np.random.randn(layer_sizes[i], layer_sizes[i-1]) * 0.01\n",
        "    return params"
      ],
      "metadata": {
        "id": "uSVBleS3aRgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initialize_params([2, 3, 4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ06u7bA0uzg",
        "outputId": "91521634-ae93-4f6d-c727-e3023bbe9ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'W1': array([[ 0.00495124,  0.0108736 ],\n",
              "        [-0.01295884,  0.01506262],\n",
              "        [-0.0096534 , -0.01010094]]),\n",
              " 'B1': array([[-0.00481749, -0.00161687],\n",
              "        [ 0.01538416, -0.00906149],\n",
              "        [ 0.0006826 , -0.00385703]]),\n",
              " 'W2': array([[-0.00331872, -0.00216686,  0.0060617 ],\n",
              "        [-0.00398092,  0.00328807, -0.01600608],\n",
              "        [-0.02852648, -0.01592398,  0.00909365],\n",
              "        [ 0.00284954, -0.03294313, -0.01531181]]),\n",
              " 'B2': array([[-0.01912949, -0.01580727, -0.00098723],\n",
              "        [ 0.01258629, -0.01010359, -0.00876762],\n",
              "        [-0.00051445,  0.01048728,  0.01152069],\n",
              "        [ 0.00996432,  0.00283932,  0.00547873]])}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X_train, params): #takes input training features and parameters as input and returns a dictionary containining the numpy arrays of activations of all layers\n",
        "    layers = len(params)//2\n",
        "    values = {}\n",
        "    for i in range(1, layers+1):\n",
        "      if i == 1:\n",
        "        values['Z' + str(i)] = np.dot(params['W' + str(i)], X_train) + params['B' + str(i)]\n",
        "        values['A' + str(i)] = relu(values['Z' + str(i)])\n",
        "      else:\n",
        "        values['Z' + str(i)] = np.dot(params['W' + str(i)], values['A' + str(i-1)]) + params['B' + str(i)]\n",
        "        if i==layers:\n",
        "            values['A' + str(i)] = values['Z' + str(i)]\n",
        "        else:\n",
        "            values['A' + str(i)] = relu(values['Z' + str(i)])\n",
        "    return values"
      ],
      "metadata": {
        "id": "Ipi1CpfLiyg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(values, Y_train): #takes true values and dictionary having activations of all layers as input and returns cost\n",
        "    layers = len(values)//2\n",
        "    Y_pred = values['A' + str(layers)]\n",
        "    cost = 1/(2*len(Y_train)) * np.sum(np.square(Y_pred - Y_train))\n",
        "    return cost"
      ],
      "metadata": {
        "id": "7b6diZnt5inn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_propagation(params, values, X_train, Y_train): #takes parameters, activations, training set as input and returns gradients wrt parameters\n",
        "    layers = len(params)//2\n",
        "    m = len(Y_train)\n",
        "    grads = {}\n",
        "    for i in range(layers, 0, -1):\n",
        "      if i == layers:\n",
        "        dA = 1/m * (values['A' + str(i)] - Y_train)\n",
        "        dZ = dA\n",
        "      else:\n",
        "        dA = np.dot(params['W' + str(i+1)].T, dZ)\n",
        "        dZ = np.multiply(dA, np.where(values['A' + str(i)]>=0, 1, 0))\n",
        "      if i==1:\n",
        "            grads['W' + str(i)] = 1/m * np.dot(dZ, X_train.T)\n",
        "            grads['B' + str(i)] = 1/m * np.sum(dZ, axis=1, keepdims=True)\n",
        "      else:\n",
        "            grads['W' + str(i)] = 1/m * np.dot(dZ,values['A' + str(i-1)].T)\n",
        "            grads['B' + str(i)] = 1/m * np.sum(dZ, axis=1, keepdims=True)\n",
        "    return grads"
      ],
      "metadata": {
        "id": "wGpcTMBg7NV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_params(params, grads, learning_rate): #takes parameters, gradients and learning rate as input and returns updated parameters\n",
        "    layers = len(params)//2\n",
        "    params_updated = {}\n",
        "    for i in range(1,layers+1):\n",
        "        params_updated['W' + str(i)] = params['W' + str(i)] - learning_rate * grads['W' + str(i)]\n",
        "        params_updated['B' + str(i)] = params['B' + str(i)] - learning_rate * grads['B' + str(i)]\n",
        "    return params_updated"
      ],
      "metadata": {
        "id": "QxTkhFPGZHcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(X_train, Y_train, layer_sizes, num_iters, learning_rate): #trains the model\n",
        "    params = initialize_params(layer_sizes)\n",
        "    for i in range(num_iters):\n",
        "      values = forward_propagation(X_train.T, params)\n",
        "      cost = compute_cost(values, Y_train.T)\n",
        "      grads = backward_propagation(params, values, X_train.T, Y_train.T)\n",
        "      params = update_params(params, grads, learning_rate)\n",
        "      print('Cost at iteration ' + str(i+1) + ' = ' + str(cost) + '\\n')\n",
        "    return params\n",
        "\n",
        "\n",
        "def compute_accuracy(X_train, X_test, Y_train, Y_test, params):\n",
        "    layers = len(params)//2\n",
        "    values_train = forward_propagation(X_train.T, params)\n",
        "    values_test = forward_propagation(X_test.T, params)\n",
        "    train_acc = np.sqrt(mean_squared_error(Y_train, values_train['A' + str(layers-1)].T))\n",
        "    test_acc = np.sqrt(mean_squared_error(Y_test, values_test['A' + str(layers-1)].T))\n",
        "    return train_acc, test_acc\n",
        "\n",
        "def predict(X, params):  #predict on new array X given learnt parameters\n",
        "    values = forward_propagation(X.T, params)\n",
        "    predictions = values['A' + str(len(values)//2)].T\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "mGvRS7uBZ9gU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}